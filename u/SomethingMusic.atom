<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom"><title type="text">u/SomethingMusic - r/TheMotte</title><id>https://themotte.srid.ca/</id><updated>2022-08-02T21:46:39Z</updated><link href="https://themotte.srid.ca/u/SomethingMusic" rel="self"/><entry><id>http://old.reddit.com/r/TheMotte/comments/wda188/culture_war_roundup_for_the_week_of_august_01_2022/iip8cht/?sort=confidence</id><title type="text">[CW] Some thoughts on Artificial general intelligence.

[Econtalk recently had guest </title><updated>2022-08-02T21:46:39Z</updated><author><name>SomethingMusic</name></author><category label="CW" scheme="https://themotte.srid.ca/cw" term="Culture War"/><content type="text">Some thoughts on Artificial general intelligence.

[Econtalk recently had guest Gerd Gigerenzer](https://www.econtalk.org/gerd-gigerenzer-on-how-to-stay-smart-in-a-smart-world/#read-comments) on how AGI is not nearly close to becoming a reality.  His blanket summary is that while computers can outperform humans in tasks, his example is Watson   winning Jeopardy, it failed miserably when being applied to other tasks such as diagnosing illnesses and creating treatments. AI thinking in probability and statistics while humans think in patterns and narratives.

&amp;gt;AlphaZero can beat every human in chess and Go, but it doesn&#39;t know that there is a game that&#39;s called chess or Go. A deep neural network, in order to learn, to distinguish pictures of, say school buses, from other objects on the street needs 10,000 pictures of school buses in order to learn that.

&amp;gt;If you have a four-year-old and point to a school bus, you may have to point another time, and then the kid has gotten it. It has a concept of a school bus.

&amp;gt;So, what I&#39;m saying: artificial intelligence, as in deep neural networks, has a very different kind of intelligence that does not resemble, much, human intelligence. Basically, to understand that deep neural networks are statistical machines that can do very powerful look for correlations. That&#39;s not the greatest ability of the human mind. We are strong in causal stories. We invent, we are looking for.

The biggest problem with AGI is not that it will think or imitate a human, but that a human believes that machines *are* thinking like humans.  Humanity is not just the external interaction between people, but also the internal thoughts, narratives, and emotions that go alongside these actions.

Despite this, we have significant needs for an AGI to be developed and deployed. There are more j[ob openings than there are employable people in the US](https://www.businessinsider.com/job-openings-june-jolts-labor-shortage-outlook-hiring-trends-quits-2022-8), and compounded with the decreased birth rate and a decreasing labor pool it will be harder and harder to fulfill these positions.  Likewise, an AGI could significantly [help secure food supply, as many parts of growing plants are still incredibly labor intensive](https://youtu.be/M2GIXU_WFC0?t=368).</content><link href="http://old.reddit.com/r/TheMotte/comments/wda188/culture_war_roundup_for_the_week_of_august_01_2022/iip8cht/?sort=confidence"/></entry></feed>
<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom"><title type="text">u/Primaprimaprima - r/TheMotte</title><id>https://themotte.srid.ca/</id><updated>2022-08-19T00:12:59Z</updated><link href="https://themotte.srid.ca/u/Primaprimaprima" rel="self"/><entry><id>http://old.reddit.com/r/TheMotte/comments/wos3do/culture_war_roundup_for_the_week_of_august_15_2022/ikva0zo/?sort=confidence</id><title type="text">[CW] **Do you like AI?**

I&#39;ve been thinking about how the discussion about AI art ca</title><updated>2022-08-19T00:12:59Z</updated><author><name>Primaprimaprima</name></author><category label="CW" scheme="https://themotte.srid.ca/cw" term="Culture War"/><content type="text">**Do you like AI?**

I&#39;ve been thinking about how the discussion about AI art can be linked back to the culture war, since that is our *raison d&#39;Ãªtre*.

Most of the discussion here has focused on the object-level issues concerning AI art: the economic impact to artists, the projected rate of progression of the technology, etc.  What I&#39;m interested in here, though, is the psychological profiles of the participants in the debate.  It&#39;s clear to me that there are people who *like AI*, and there are people who *don&#39;t like AI*.  That is, regardless of your object-level beliefs about the inevitability of the development of the technology, or how many jobs it will displace, or what potential benefits it may bring to society and culture at large, people tend to enter the debate with a preexisting positive or negative emotional affect towards the concept of AI itself.  Some people are happy that the technology exists; some are not.

What causes someone to join one group or the other?  What sorts of underlying beliefs and values are at play here?  What patterns can we observe?

To make things clear up front, I *don&#39;t like* AI, and I especially don&#39;t like AI art, so part of the analysis will inevitably take place from that point of view, although I ultimately hope to touch on the underlying psychological motivations of both groups.

Let&#39;s dispose of some of the simple and obvious explanations first: the idea, for example, that the only people worried about AI art are artists who are afraid of losing their jobs, and any other sane person should be happy to reap the rewards of increasingly democratized access to the means of cultural production.  I can&#39;t object to this idea from an *entirely* neutral point of view, since drawing and painting are more tied to my identity than they are for the average person, but I can still object to it from a semi-objective point of view.  I have no musical ability whatsoever, nor do I have any interest in ever developing any, but I still don&#39;t like AI music.  I&#39;m pretty sure it&#39;s been years at this point since I first heard about AI composing pieces in the style of Bach and Beethoven, and I didn&#39;t like that stuff when I first heard about it either.  It rubs me the wrong way.

Nor can opposition to AI be reduced to simple technological luddism, or a knee-jerk preference for what is familiar over what is new and unfamiliar.  I am not opposed to all technological progress on principle - I welcome the advent of interstellar travel, and the curing of diseases like cancer and ALS.  Conversely, I am skeptical of technologies that have been a familiar part of my life since childhood.  I can hardly remember a time when I didn&#39;t have access to the internet, and yet my feelings towards it are mixed at best.  It&#39;s a double edged sword - it has brought many great things, but also many terrible things.  If I could somehow freeze publicly-available internet access at a level of development comparable to the late 90s, I probably would.  But that&#39;s another story.

It&#39;s not hard to enumerate factors that I *incidentally* find distasteful about AI art - that it will flood the world with a glut of low-effort content, that it will inflate the egos of people who think they are &#34;artists&#34; when they are in fact nothing of the sort, that it will discourage people from developing genuine creativity because it will be easier to settle for a half-hearted, inauthentic substitute - but I think that none of these considerations truly strike at the heart of the issue for me.  My intuition is that there is something deeper going on, something that can be related to the culture war, because I think I can see familiar patterns from the culture war repeating themselves.

My highly speculative thesis is that people who like AI are motivated by an *aesthetics of success*, and people who don&#39;t like AI are motivated by an *aesthetics of failure*, or a tragic aesthetics.  These positions also correspond in a very loose way to the left/right divide, respectively.  I&#39;ll try to explain what I mean.

Traditionally, leftism since Marx was founded in a belief in utopian progress - that we could resolve social problems through willful, rational action, ultimately culminating in a terminal optimal social order that was free of contradictions, or as Marx put it, &#34;the riddle of history solved&#34;.  Now, it&#39;s possible to claim that modern (or even classic) leftism is not about this at all, and that it&#39;s actually a thinly disguised form of ethnic warfare.  That may be true.  But even so, you can&#39;t deny that this utopian impulse did exist in and continues to inform leftism, and more importantly, people who *enjoy* this vision of the future, people who find it *aesthetically* pleasing, people who hear the idea of an optimal non-contradictory social order and think &#34;hey that sounds like a good idea&#34;, tend to be drawn to leftism.

The same utopian impulse from Marxism also underlies the transhumanism of, for example, Yudkowsky&#39;s [Fun Theory](https://www.lesswrong.com/posts/K4aGvLnHvYgX9pZHS/the-fun-theory-sequence).  The idea (as far as I can tell from lightly skimming it) is that we could construct a perfect reality that satisfies every constraint we could ever wish to optimize for - it&#39;s exactly as exciting as we need, exactly as pleasant as we need, exactly as challenging as we need, and if for some reason you wish to meet a tragic end where you fail to fulfill all your goals, well hey we can arrange for that too.  It is logically perfect in every way - no one is excluded, no one could ask for more, even the people whose very wish is to be excluded from the utopia.  I think the relation between this kind of transhumanism on the one hand, and the development of AI on the other, is pretty obvious - if you enjoy, on an aesthetic level, the idea of a perfect transhumanist future, then you probably also enjoy on an aesthetic level when AI smashes through fundamental human limitations.

I am *in no way* saying that everyone who gets warm fuzzies for AI and transhumanism is a leftist.  Certainly we have many counterexamples on this forum.  Nor does every leftist like the idea of AI - there are plenty of leftist artists complaining on twitter about AI art as we speak.  But I do think that leftists and people who like AI are aligned on this general pro-utopian axis - they agree that a utopian future is fundamentally desirable, even if they disagree on implementation details, and many other contemporary political issues besides.

The key thing to understand about the other side, the opposition to this utopian ideal, is that *not everyone thinks that utopia is desirable*.  Some of us consciously reject it.  I mean this in a very deep way, as deep as you can possibly conceive.  I mean that even in the most logically perfect utopia you can imagine, one where everyone gets the exact amount of challenge and pain and tragedy that is suited to them, one where I can live in my tragic broken reality and you can live in your blissful nice one and we can somehow coexist simultaneously - *I still don&#39;t want that*.  I don&#39;t want reality to be like that.  I don&#39;t want reality to be at peace.  I want there to be failure in the very nature of things.  I want us to never reach a final state of peace, even if there is fire and brimstone built into that overarching peace.

From Zizek&#39;s &#34;Less Than Nothing&#34;:

&amp;gt;It is true that one finds in Hegel a systematic drive to cover everything, to propose an account of all phenomena in the universe in their essential structure; but this drive does not mean that Hegel strives to locate every phenomenon within a harmonious global edifice; on the contrary, the point of dialectical analysis is to demonstrate how every phenomenon, everything that happens, fails in its own way, implies a crack, antagonism, imbalance, in its very heart.  Hegel&#39;s gaze upon reality is that of a Roentgen apparatus which sees in everything that is alive the traces of its future death.

I find this to be an immensely aesthetically pleasing passage - it&#39;s how I want reality to be.  I imagine that transhumanists will not feel as warmly towards it (although this is an empirical hypothesis that is subject to refutation through counterexamples).  To you, there is beauty in triumph; problems are meant to be solved, and then quietly and safely set aside, conquered, dealt with.  You want to [resolve on the I chord](https://youtu.be/6aezSL_GvZA?t=430).  We won, you say; there&#39;s no need to go backwards now.  Man stands victorious at the summit of his knowledge.  You thought we couldn&#39;t make a machine that paints beautiful pictures?  Well, we did it.  We put the sum total of man&#39;s visual knowledge into a machine.  That&#39;s what we were able to accomplish; our triumph over this domain is total.  The beauty of our actions is measured by the strength of the gods we have slain.

To me, there is beauty in failure - no problem ever fully solved, no debate ever put to rest, no point of finality ever reached.  Not because there is an angry God who will slap us down if we exceed our station, but because *failure is built into the very nature of things*.  The moment of triumph becomes the moment of defeat, not due to any external force, but because of the necessity of its own inner movement.  Reality as a demonic house of mirrors where every moment of recognition is the moment of misrecognition, every realization comes too late that the act of will was actually the ultimate act of self-sabotage - this is reality as I *aesthetically* want it to be.  Doesn&#39;t mean it is.  But it&#39;s what I want - it&#39;s what I like.  And our likes and dislikes are awfully important when it comes to motivating our actions.

Hopefully there&#39;s something here to discuss.

&amp;gt;Out of love for mankind... I conceived it as my task to create difficulties everywhere.

- Kierkegaard</content><link href="http://old.reddit.com/r/TheMotte/comments/wos3do/culture_war_roundup_for_the_week_of_august_15_2022/ikva0zo/?sort=confidence"/></entry></feed>